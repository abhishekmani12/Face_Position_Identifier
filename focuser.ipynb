{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b06aa238-4445-40eb-8f79-6cd6e3f273e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54e8dd7f-950c-44e5-a617-8d2938d7efdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseobj=mp.solutions.face_mesh\n",
    "base_model=baseobj.FaceMesh(min_detection_confidence=0.4, min_tracking_confidence=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a3657244-7033-4de9-9ab0-88f2f07f0769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OFF Focus WARNING:  1\n",
      "OFF Focus WARNING:  2\n",
      "OFF Focus WARNING:  3\n",
      "OFF Focus WARNING:  4\n",
      "OFF Focus WARNING:  5\n",
      "OFF Focus WARNING:  6\n",
      "OFF Focus WARNING:  7\n"
     ]
    }
   ],
   "source": [
    "track=\"focused\"\n",
    "count=0\n",
    "cap =cv2.VideoCapture(0)\n",
    "while cap.isOpened():\n",
    "    s, img=cap.read()\n",
    "    \n",
    "    img=cv2.cvtColor(img,cv2.COLOR_BGR2RGB) #fm requires rgb input\n",
    "    landmarks=base_model.process(img) #get keypoint landmarks mesh for a face\n",
    "    img=cv2.cvtColor(img,cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "    #Extracting eye edge(left - 33, right - 263), nose(1), mouth edge(left - 61, right - 291), chin(199) keypoint landmarks\n",
    "\n",
    "    twoD=[] #x,y\n",
    "    threeD=[] #axis\n",
    "    \n",
    "    h, w, c=img.shape\n",
    "    \n",
    "    if landmarks.multi_face_landmarks:\n",
    "        for dat in landmarks.multi_face_landmarks:\n",
    "            for i, cood in enumerate(dat.landmark):\n",
    "                    if i == 33 or i == 263 or i == 1 or i == 61 or i == 291 or i == 199:\n",
    "\n",
    "                        x=int(cood.x*w) #multiplying width to x cood and height to y cood\n",
    "                        y=int(cood.y*h)\n",
    "                        z=cood.z\n",
    "\n",
    "\n",
    "                        twoD.append([x,y])\n",
    "                    \n",
    "\n",
    "                        threeD.append([x,y,z])\n",
    "                    \n",
    "\n",
    "            twoD=np.array(twoD, dtype=np.float64)\n",
    "            threeD=np.array(threeD, dtype=np.float64)\n",
    "                    \n",
    "                    \n",
    "            focalpoint=1*w #fx, fy\n",
    "            skew=0 #gamma\n",
    "            u_cood=h/2\n",
    "            v_cood=w/2\n",
    "\n",
    "            #camera matrix\n",
    "\n",
    "            cam_mat=np.array([\n",
    "                                [focalpoint, 0, u_cood],\n",
    "                                [0, focalpoint, v_cood],\n",
    "                                [0, 0, 1]\n",
    "                            ])\n",
    "\n",
    "            #distance matrix\n",
    "            dist_mat=np.zeros((4,1), dtype=np.float64)\n",
    "\n",
    "            #pnp - convert 3d point in obj cood frame to 2d camera cood frame by getting rotation and translation vectors\n",
    "            s, rot_v, trans_v=cv2.solvePnP(threeD, twoD, cam_mat, dist_mat)\n",
    "\n",
    "            rot_mat, _ = cv2.Rodrigues(rot_v) # convert to matrix to get rot angle\n",
    "\n",
    "            angle, mtxR, mtxQ, Qx, Qy, Qz = cv2.RQDecomp3x3(rot_mat) #extract angles\n",
    "\n",
    "            xdegree=angle[0]*360\n",
    "            ydegree=angle[1]*360\n",
    "\n",
    "            if ydegree < -10 or ydegree > 10 or xdegree < -4:\n",
    "                current=\"Not focused\"\n",
    "            else:\n",
    "                current=\"focused\"\n",
    "                \n",
    "            \n",
    "            if track == \"Not focused\" and current == \"focused\":\n",
    "                    count+=1\n",
    "                    print(\"OFF Focus WARNING: \",count)\n",
    "                    \n",
    "            track=current       \n",
    "            \n",
    "                        \n",
    "            #cv2.putText(img, current, (20, 20), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "    cv2.imshow('focus', img)\n",
    "                    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('f'):\n",
    "        break\n",
    "                \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
